{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AT - Engenharia de Prompts para Ci√™ncia de Dados [24E4_4]\n",
    "\n",
    "**Rafael Soares de Oliveira**\n",
    "\n",
    "Infnet - Ci√™ncia de Dados | Dezembro 2024\n",
    "\n",
    "https://lms.infnet.edu.br/moodle/mod/assign/view.php?id=413838\n",
    "\n",
    "> üí° **Reposit√≥rio GitHub:** https://github.com/RafaelOlivra/infnet-at-engenharia-de-prompts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exerc√≠cio 1: Arquitetura da Solu√ß√£o\n",
    "\n",
    "Desenvolva um prompt que utilize few-shot learning para classificar coment√°rios como ‚ÄúPositivos‚Äù, ‚ÄúNeutros‚Äù ou ‚ÄúNegativos‚Äù. Inclua tr√™s exemplos de cada categoria no prompt e solicite ao LLM que classifique a frase \"Este epis√≥dio √© divertido, mas n√£o t√£o bom quanto os antigos.\". Interprete o resultado.\n",
    "\n",
    "Desenhe a arquitetura da solu√ß√£o com o programa da sua escolha. A arquitetura deve indicar os pontos de processamento de informa√ß√£o, LLMs utilizados, bases de dados (parquets, jsons e faiss), arquivos de configura√ß√£o (yaml), abas do dashboard e suas funcionalidades.\n",
    "\n",
    "-   Exporte a arquitetura para o arquivo pdf importado no sistema.\n",
    "-   Descreva a arquitetura, explicando seus pontos importantes.\n",
    "-   Descreva o funcionamento de LLMs e como isso pode ser utilizado para atividades de sumariza√ß√£o.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Diagrama](./images/exec1-diagrama-aplicacao.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìù O dashboard utiliza dados extra√≠dos da API da C√¢mara dos Deputados (https://dadosabertos.camara.leg.br/api/v2/). Esses dados s√£o processados no arquivo dataprep.py, onde ocorre a gera√ß√£o, sumariza√ß√£o e indexa√ß√£o de conte√∫do com o aux√≠lio do LLM Gemini e do vetorizador FAISS. Ap√≥s o processamento, os dados s√£o exportados nos formatos .parquet e .json.\n",
    ">\n",
    "> No arquivo dashboard.py, foi desenvolvido um aplicativo Streamlit com tr√™s abas principais: Overview, Despesas e Proposi√ß√µes. Essas abas utilizam os dados previamente preparados para criar uma interface interativa que facilita a visualiza√ß√£o das informa√ß√µes.\n",
    "> \n",
    "> Na aba Proposi√ß√µes, h√° tamb√©m uma interface de chat integrada com o LLM Gemini. Essa funcionalidade permite que o usu√°rio fa√ßa perguntas e obtenha insights sobre os dados processados, utilizando um sistema RAG (Retrieval-Augmented Generation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìù Large Language Models (LLMs) s√£o modelos de intelig√™ncia artificial treinados em grandes volumes de texto para entender e gerar linguagem natural. Eles utilizam mecanismos como aten√ß√£o para identificar as partes mais relevantes de um texto, tornando-se ideais para tarefas como gera√ß√£o de conte√∫do e sumariza√ß√£o.\n",
    ">\n",
    "> Na gera√ß√£o de texto, os LLMs podem criar conte√∫dos originais, como respostas em chats, artigos ou relat√≥rios, adaptando-se ao contexto e at√© podendo gerar textos com base em um estilo desejado.\n",
    "Na sumariza√ß√£o, os LLMs condensam textos extensos, destacando informa√ß√µes importantes ou ainda reformulando o conte√∫do de forma mais clara. Isso √© √∫til em aplica√ß√µes como dashboards e chats, onde resumos e textos personalizados facilitam a an√°lise, a comunica√ß√£o e a tomada de decis√µes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exerc√≠cio 2: Cria√ß√£o de Textos com LLMs\n",
    "\n",
    "Utilize a sua conta no ‚Äúpoe.com‚Äù para gerar um texto curto (2 par√°grafos) que explique a C√¢mara dos Deputados. Execute o mesmo prompt com 3 LLMs diferentes (claude, gemini e chatgpt) e:\n",
    "\n",
    "-   Explique as vantagens e desvantagens dos tr√™s LLMs escolhidos.\n",
    "-   Argumente sobre a diferen√ßa entre a resposta dos 3 LLMs\n",
    "-   Justifique a escolha da resposta final\n",
    "\n",
    "-   Atualize o prompt do LLM final para gerar um arquivo data/config.yaml com a resposta final (chave: overview_summary).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Claude**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Claude](./images/exec2-a.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gemini**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Gemini](./images/exec2-b.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chat GPT**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ChatGPT](./images/exec2-c.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìù O ChatGPT, desenvolvido pela OpenAI, √© atualmente a principal escolha para tarefas cotidianas, como ajuda na reda√ß√£o de textos, corre√ß√µes e esclarecimento de d√∫vidas b√°sicas. Ele possui um entendimento amplo sobre uma vasta gama de t√≥picos, gerando textos coerentes e com naturalidade impressionante. Baseado na arquitetura GPT-4, o ChatGPT √© uma ferramenta poderosa. No entanto, apesar de todos esses avan√ßos, ainda pode produzir respostas incorretas ou enviesadas dependendo do prompt utilizado. Al√©m disso, seu custo √© mais elevado em compara√ß√£o com concorrentes.\n",
    ">\n",
    "> O Gemini, desenvolvido pela Google, destaca-se por produzir respostas concisas e seguras, contando com diversos filtros para bloquear conte√∫dos inadequados. Projetado para minimizar vieses em suas respostas, o Gemini tamb√©m se diferencia por sua arquitetura multimodal, permitindo combinar texto, imagens e outros formatos de dados de maneira integrada. Uma desvantagem relevante √© a forma como os dados fornecidos pelos usu√°rios podem ser utilizados, j√° que a Google declara que essas informa√ß√µes podem ser usadas para melhorar seus produtos e servi√ßos, o que, em alguns casos, levanta preocupa√ß√µes sobre invas√£o de privacidade.\n",
    ">\n",
    "> O Claude, criado pela Anthropic, √© outro chatbot projetado com foco em seguran√ßa e princ√≠pios √©ticos incorporados. Ele se adapta bem a contextos mais espec√≠ficos e, at√© o momento, oferece modelos com custos mais acess√≠veis (Dependendo do modelo), entregando um bom custo-benef√≠cio. No entanto, uma limita√ß√£o do Claude √© a menor presen√ßa de sua comunidade no conte√∫do em portugu√™s, o que pode representar uma desvantagem em solu√ß√µes voltadas para o mercado local.\n",
    "\n",
    "> üìù A resposta do Claude foi um pouco mais breve do que o esperado, deixando a desejar em alguns aspectos. J√° as respostas do Gemini e do ChatGPT foram bastante similares, tanto no formato quanto no conte√∫do, que foi satisfat√≥rio em ambos os casos.\n",
    "\n",
    "> üìù Optei por seguir com a resposta do ChatGPT por consider√°-la mais concisa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Gera√ß√£o de Yaml](./images/exec2-d.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exerc√≠cio 3: Processamento dos dados de deputados\n",
    "\n",
    "Implemente em dataprep.py uma fun√ß√£o que fa√ßa a coleta das informa√ß√µes dos deputados atuais da c√¢mara dos deputados:\n",
    "\n",
    "-   Colete e salve os dados dos deputados atuais da c√¢mara no arquivo data/deputados.parquet atrav√©s da url: url_base+/deputados\n",
    "-   Executar prompt para criar o c√≥digo que gere um gr√°fico de pizza com o total e o percentual de deputados de cada partido, salvo em 'docs/distribuicao_deputados.png\n",
    "-   Executar prompt utilizando os resultados da an√°lise anterior (distribui√ß√£o de deputados por partido) para gerar insights sobre a distribui√ß√£o de partidos e como isso influencia a c√¢mara. Utilize os elementos de prompts dados, persona e exemplos para instruir o LLM. Explique o objetivo de cada elemento, avalie a resposta e salve-a em data/insights_distribuicao_deputados.json.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìù A resposta se encontra em `dataprep.py`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exerc√≠cio 4: Processamento dos dados de despesas\n",
    "\n",
    "Implemente em dataprep.py uma fun√ß√£o que colete as informa√ß√µes das despesas dos deputados atuais da c√¢mara dos deputados no per√≠odo de refer√™ncia da solu√ß√£o (use a url: url_base+/deputados/{id}/despesas).\n",
    "\n",
    "-   Agrupe os dados de despesas por dia, deputado e tipo de despesa e salve num arquivo parquet (data/serie_despesas_di√°rias_deputados.parquet).\n",
    "-   Utilizando a t√©cnica de prompt-chaining, crie um prompt que instrua o LLM a gerar um c√≥digo python que analise os dados das despesas dos deputados. Pe√ßa para o LLM at√© 3 an√°lises. Indique ao LLM quais dados est√£o dispon√≠veis e o respectivo arquivo (salvo em a)) e execute as an√°lises.\n",
    "-   Utilize os resultados das 3 an√°lises para criar um prompt usando a t√©cnica de Generated Knowledge para instruir o LLM a gerar insights. Salve o resultado como um JSON (data/insights_despesas_deputados.json).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìù A resposta se encontra em `dataprep.py`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exerc√≠cio 5: Processamento dos dados de proposi√ß√µes\n",
    "\n",
    "Implemente em dataprep.py uma fun√ß√£o que fa√ßa a coleta das informa√ß√µes das proposi√ß√µes que tramitam no per√≠odo de refer√™ncia (dataInicio e dataFim) e s√£o do tema 'Economia', 'Educa√ß√£o' e 'Ci√™ncia, Tecnologia e Inova√ß√£o' (c√≥digos [40, 46, 62]).\n",
    "\n",
    "-   Coletar um total de 10 proposi√ßoes por tema e salvar em data/proposicoes_deputados.parquet\n",
    "-   Utilize a sumariza√ß√£o por chunks para resumir as proposi√ß√µes tramitadas no per√≠odo de refer√™ncia. Avalie a resposta e salve-a em data/sumarizacao_proposicoes.json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìù A resposta se encontra em `dataprep.py`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exerc√≠cio 6: Dashboards com Chain-of-thoughts\n",
    "\n",
    "Utilize 3 etapas de Chain-of-Thought prompting para escrever o c√≥digo inicial do dashboard, destacando as abas Overview, Despesas e Proposi√ß√µes. Explique o objetivo de cada prompt na evolu√ß√£o do c√≥digo at√© o arquivo dashboard.py final:\n",
    "\n",
    "-   A aba Overview deve possuir um t√≠tulo e descri√ß√£o da solu√ß√£o de sua escolha.\n",
    "-   O painel deve mostrar o texto sumarizado em config.yaml\n",
    "-   O painel deve mostrar o gr√°fico de barras em docs/distribuicao_deputados.png\n",
    "-   O painel deve mostrar os insights do LLM sobre a distribui√ß√£o de deputados em data/insights_distribuicao_deputados.json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìù Os c√≥digos se encontram em `dataprep.py` e `dashboard.py`.\n",
    ">\n",
    "> No primeiro prompt, a ideia foi criar o arquivo inicial com um esqueleto geral de como tudo deveria ser organizado, j√° incluindo o t√≠tulo e o sum√°rio gerado anteriormente.\n",
    ">\n",
    "> No segundo prompt, eu estava interessado apenas no c√≥digo para exibir a imagem do gr√°fico, ent√£o informei ao LLM sobre a exist√™ncia do dashboard anterior, para que o foco fosse exclusivamente na inclus√£o dessa imagem.\n",
    ">\n",
    "> O √∫ltimo prompt seguiu uma l√≥gica semelhante √† do anterior, mas com foco em exibir os insights salvos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exerc√≠cio 7: Dashboards com Batch-prompting\n",
    "\n",
    "Utilize a t√©cnica de Batch-prompting para escrever o c√≥digo streamlit que preencha as abas Despesas e Proposi√ß√µes do c√≥digo em dashboard.py. O prompt deve descrever com detalhes cada aba para gera√ß√£o de:\n",
    "\n",
    "-   Aba Despesas deve mostrar os insights sobre as despesas dos deputados (data/insights_despesas_deputados.json)\n",
    "-   Aba Despesas deve conter um st.selectbox para sele√ß√£o do deputado.\n",
    "-   Aba Despesas deve mostrar gr√°fico de barras com a s√©rie temporal de despesas do deputado selecionado (data/serie_despesas_di√°rias_deputados.parquet).\n",
    "-   O painel deve mostrar uma tabela com os dados das proposi√ß√µes (data/proposicoes_deputados.parquet)\n",
    "-   O painel deve mostrar o resumo das proposi√ß√µes em (data/sumarizacao_proposicoes.json)\n",
    "-   Compare o resultado dos c√≥digos gerados pelas t√©cnicas de Chain-of-Thoughts e Batch-prompting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìù Os c√≥digos se encontram em `dataprep.py` e `dashboard.py`.\n",
    ">\n",
    "> Acredito que essa t√©cnica seja superior ao COT (pelo menos neste caso), pois considero que a LLM tenha mais contexto para gerar um c√≥digo mais eficiente e que se conecte melhor. No COT, √© necess√°rio ficar relembrando a LLM sobre o que j√° foi feito e dar dicas do que n√£o refazer, evitando processamento desnecess√°rio. \\\n",
    "> No batch, fica mais f√°cil fazer ajustes finos no prompt final sem se preocupar que isso afete os prompts seguintes.\n",
    "> Por outro lado, acredito que o batch prompting requeira mais processamento e possa exaurir a mem√≥ria da LLM se feito de forma exagerada. \\\n",
    "> Em termos de funcionalidade, as duas t√©cnicas geraram um c√≥digo final que funcionou.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exerc√≠cio 8: Dashboards com Batch-prompting\n",
    "\n",
    "Adicione ao c√≥digo da aba Proposi√ß√µes uma interface para chat com um assistente virtual especialista em c√¢mara dos deputados. As informa√ß√µes coletadas dos deputados, despesas e proposi√ß√µes (e suas sumariza√ß√µes) devem ser vetorizadas usando o modelo \"neuralmind/bert-base-portuguese-cased\" para armazenamento na base vetorial FAISS. O prompt do sistema para o assistente virtual deve ser feito com a t√©cnica Self-Ask:\n",
    "\n",
    "-   Explique como a t√©cnica de self-ask pode ser utilizada nesse contexto.\n",
    "-   Avalie o resultado do modelo para as seguintes perguntas:\n",
    "    -   Qual √© o partido pol√≠tico com mais deputados na c√¢mara?\n",
    "    -   Qual √© o deputado com mais despesas na c√¢mara?\n",
    "    -   Qual √© o tipo de despesa mais declarada pelos deputados da c√¢mara?\n",
    "    -   Quais s√£o as informa√ß√µes mais relevantes sobre as proposi√ß√µes que falam de Economia?\n",
    "    -   Quais s√£o as informa√ß√µes mais relevantes sobre as proposi√ß√µes que falam de 'Ci√™ncia, Tecnologia e Inova√ß√£o'?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìù Os c√≥digos se encontram em `dashboard.py`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Exec 8a](./images/exec8-a.png)\n",
    "\n",
    "> üìù A resposta est√° errada! Por√©m a conclus√£o do modelo bate com os dados que ele recebeu do RAG. O modelo acabou informando o usu√°rio sobre esse limita√ß√£o, o que achei interessante.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Exec 8b](./images/exec8-b.png)\n",
    "\n",
    "> üìù De forma similar a resposta anterior, o modelo respondeu corretamente se considerado apenas o RAG. Por√©m n√£o d√° para ter certeza, visto que os dados que o modelo recebeu s√£o limitados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Exec 8c](./images/exec8-c.png)\n",
    "\n",
    "> üìù Novamente acredito que o modelo se saiu bem, por√©m a quantidade de dados fornecida pelo RAG √© limitada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Exec 8d](./images/exec8-d.png)\n",
    "\n",
    "> üìù Acredito que o modelo se saiu muito bem nessa quest√£o, dando um resumo bem satisfat√≥rio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Exec 8e](./images/exec8-e.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìù Gostei da reposta, o modelo utilizou muito bem os dados fornecidos pelo RAG e trouxe um resumo bem satisfat√≥rio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exerc√≠cio 9: Gera√ß√£o de Imagens com Prompts\n",
    "\n",
    "Utilizando as informa√ß√µes sumarizadas das proposi√ß√µes dos deputados, vamos gerar prompts que possam fazer alus√£o aos temas e o que est√° sendo proposto. Use o google Colab para gerar imagens com o modelo \"CompVis/stable-diffusion-v1-4\" para duas proposi√ß√µes de sua escolha. Com essas informa√ß√µes, responda:\n",
    "\n",
    "Descreva o funcionamento dos modelo de imagem, segundo suas arquiteturas, limita√ß√µes e vantagens:\n",
    "Stable Diffusion\n",
    "DALL-e\n",
    "MidJourney\n",
    "Utilize diferentes t√©cnicas de ‚ÄúEstilo Visual‚Äù e ‚ÄúComposi√ß√£o‚Äù, al√©m de exemplos com negative prompting, para gerar 3 vers√µes de imagem para cada proposi√ß√£o e avalie as diferen√ßas entre os resultados (as imagens) e os prompts (as proposi√ß√µes).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìù Link para o colab: https://colab.research.google.com/drive/1Fj5JJSbotnVDR1HgjE4uycv5vjUllZlT?usp=sharing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìù Stable Diffusion √© um modelo open-source baseado em difus√£o latente, eficiente em termos de computa√ß√£o e capaz de rodar em GPUs comuns. Ele suporta t√©cnicas como inpainting e prompting negativo, mas geralmente apresenta qualidade inferior em compara√ß√£o a modelos mais especializados.\n",
    ">\n",
    "> DALL-E utiliza uma arquitetura baseada em Transformers para gerar imagens a partir de descri√ß√µes textuais. √â um modelo bastante eficaz na interpreta√ß√£o de prompts, mas possui certa limita√ß√£o quanto √† personaliza√ß√£o e requer um dom√≠nio de t√©cnicas avan√ßadas de composi√ß√£o. A qualidade das imagens pode variar bastante.\n",
    ">\n",
    "> MidJourney √© desenvolvido pela MidJourney, Inc. Ele √© otimizado para criar imagens estilizadas e com est√©tica art√≠stica, e possui uma abordagem amig√°vel, operando atrav√©s de chats no Discord. Possui menor precis√£o para descri√ß√µes t√©cnicas e detalhadas. √â um servi√ßo pago e de c√≥digo fechado, embora permita a cria√ß√£o de algumas imagens no free-tier.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
