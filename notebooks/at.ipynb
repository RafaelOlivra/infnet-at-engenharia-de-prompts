{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AT - Engenharia de Prompts para Ci√™ncia de Dados [24E4_4]\n",
    "\n",
    "**Rafael Soares de Oliveira**\n",
    "\n",
    "Infnet - Ci√™ncia de Dados | Dezembro 2024\n",
    "\n",
    "https://lms.infnet.edu.br/moodle/mod/assign/view.php?id=413838\n",
    "\n",
    "> üí° **Reposit√≥rio GitHub:** ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exerc√≠cio 1: Arquitetura da Solu√ß√£o\n",
    "\n",
    "Desenvolva um prompt que utilize few-shot learning para classificar coment√°rios como ‚ÄúPositivos‚Äù, ‚ÄúNeutros‚Äù ou ‚ÄúNegativos‚Äù. Inclua tr√™s exemplos de cada categoria no prompt e solicite ao LLM que classifique a frase \"Este epis√≥dio √© divertido, mas n√£o t√£o bom quanto os antigos.\". Interprete o resultado.\n",
    "\n",
    "Desenhe a arquitetura da solu√ß√£o com o programa da sua escolha. A arquitetura deve indicar os pontos de processamento de informa√ß√£o, LLMs utilizados, bases de dados (parquets, jsons e faiss), arquivos de configura√ß√£o (yaml), abas do dashboard e suas funcionalidades.\n",
    "\n",
    "- Exporte a arquitetura para o arquivo pdf importado no sistema.\n",
    "- Descreva a arquitetura, explicando seus pontos importantes.\n",
    "- Descreva o funcionamento de LLMs e como isso pode ser utilizado para atividades de sumariza√ß√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exerc√≠cio 2:  Cria√ß√£o de Textos com LLMs\n",
    "\n",
    "Utilize a sua conta no ‚Äúpoe.com‚Äù para gerar um texto curto (2 par√°grafos) que explique a C√¢mara dos Deputados. Execute o mesmo prompt com 3 LLMs diferentes (claude, gemini e chatgpt) e:\n",
    "\n",
    "- Explique as vantagens e desvantagens dos tr√™s LLMs escolhidos.\n",
    "- Argumente sobre a diferen√ßa entre a resposta dos 3 LLMs\n",
    "- Justifique a escolha da resposta final\n",
    "\n",
    "- Atualize o prompt do LLM final para gerar um arquivo data/config.yaml com a resposta final (chave: overview_summary)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Claude**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Claude](./images/exec2-a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gemini**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Gemini](./images/exec2-b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chat GPT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ChatGPT](./images/exec2-c.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìù O ChatGPT, desenvolvido pela OpenAI, √© atualmente a principal escolha para tarefas cotidianas, como ajuda na reda√ß√£o de textos, corre√ß√µes e esclarecimento de d√∫vidas b√°sicas. Ele possui um entendimento amplo sobre uma vasta gama de t√≥picos, gerando textos coerentes e com naturalidade impressionante. Baseado na arquitetura GPT-4, o ChatGPT √© uma ferramenta poderosa. No entanto, apesar de todos esses avan√ßos, ainda pode produzir respostas incorretas ou enviesadas dependendo do prompt utilizado. Al√©m disso, seu custo √© mais elevado em compara√ß√£o com concorrentes.\n",
    ">\n",
    "> O Gemini, desenvolvido pela Google, destaca-se por produzir respostas concisas e seguras, contando com diversos filtros para bloquear conte√∫dos inadequados. Projetado para minimizar vieses em suas respostas, o Gemini tamb√©m se diferencia por sua arquitetura multimodal, permitindo combinar texto, imagens e outros formatos de dados de maneira integrada. Uma desvantagem relevante √© a forma como os dados fornecidos pelos usu√°rios podem ser utilizados, j√° que a Google declara que essas informa√ß√µes podem ser usadas para melhorar seus produtos e servi√ßos, o que, em alguns casos, levanta preocupa√ß√µes sobre invas√£o de privacidade.\n",
    ">\n",
    "> O Claude, criado pela Anthropic, √© outro chatbot projetado com foco em seguran√ßa e princ√≠pios √©ticos incorporados. Ele se adapta bem a contextos mais espec√≠ficos e, at√© o momento, oferece modelos com custos mais acess√≠veis (Dependendo do modelo), entregando um bom custo-benef√≠cio. No entanto, uma limita√ß√£o do Claude √© a menor presen√ßa de sua comunidade no conte√∫do em portugu√™s, o que pode representar uma desvantagem em solu√ß√µes voltadas para o mercado local.\n",
    "\n",
    "\n",
    "> üìù A resposta do Claude foi um pouco mais breve do que o esperado, deixando a desejar em alguns aspectos. J√° as respostas do Gemini e do ChatGPT foram bastante similares, tanto no formato quanto no conte√∫do, que foi satisfat√≥rio em ambos os casos.\n",
    "\n",
    "> üìù Optei por seguir com a resposta do ChatGPT por consider√°-la mais concisa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Gera√ß√£o de Yaml](./images/exec2-d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exerc√≠cio 3:  Processamento dos dados de deputados\n",
    "\n",
    "Implemente em dataprep.py uma fun√ß√£o que fa√ßa a coleta das informa√ß√µes dos deputados atuais da c√¢mara dos deputados:\n",
    "\n",
    "- Colete e salve os dados dos deputados atuais da c√¢mara no arquivo data/deputados.parquet atrav√©s da url: url_base+/deputados\n",
    "- Executar prompt para criar o c√≥digo que gere um gr√°fico de pizza com o total e o percentual de deputados de cada partido, salvo em 'docs/distribuicao_deputados.png\n",
    "- Executar prompt utilizando os resultados da an√°lise anterior (distribui√ß√£o de deputados por partido) para gerar insights sobre a distribui√ß√£o de partidos e como isso influencia a c√¢mara. Utilize os elementos de prompts dados, persona e exemplos para instruir o LLM. Explique o objetivo de cada elemento, avalie a resposta e salve-a em data/insights_distribuicao_deputados.json."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìù A resposta se encontra em `dataprep.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exerc√≠cio 4: Processamento dos dados de despesas\n",
    "\n",
    "Implemente em dataprep.py uma fun√ß√£o que colete as informa√ß√µes das despesas dos deputados atuais da c√¢mara dos deputados no per√≠odo de refer√™ncia da solu√ß√£o (use a url: url_base+/deputados/{id}/despesas).\n",
    "\n",
    "- Agrupe os dados de despesas por dia, deputado e tipo de despesa e salve num arquivo parquet (data/serie_despesas_di√°rias_deputados.parquet).\n",
    "- Utilizando a t√©cnica de prompt-chaining, crie um prompt que instrua o LLM a gerar um c√≥digo python que analise os dados das despesas dos deputados. Pe√ßa para o LLM at√© 3 an√°lises. Indique ao LLM quais dados est√£o dispon√≠veis e o respectivo arquivo (salvo em a)) e execute as an√°lises.\n",
    "- Utilize os resultados das 3 an√°lises para criar um prompt usando a t√©cnica de Generated Knowledge para instruir o LLM a gerar insights. Salve o resultado como um JSON (data/insights_despesas_deputados.json)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìù A resposta se encontra em `dataprep.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exerc√≠cio 5: Processamento dos dados de proposi√ß√µes\n",
    "\n",
    "Implemente em dataprep.py uma fun√ß√£o que fa√ßa a coleta das informa√ß√µes das proposi√ß√µes que tramitam no per√≠odo de refer√™ncia (dataInicio e dataFim) e s√£o do tema 'Economia', 'Educa√ß√£o' e 'Ci√™ncia, Tecnologia e Inova√ß√£o' (c√≥digos [40, 46, 62]).\n",
    "\n",
    "- Coletar um total de 10 proposi√ßoes por tema e salvar em data/proposicoes_deputados.parquet\n",
    "- Utilize a sumariza√ß√£o por chunks para resumir as proposi√ß√µes tramitadas no per√≠odo de refer√™ncia. Avalie a resposta e salve-a em data/sumarizacao_proposicoes.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìù A resposta se encontra em `dataprep.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exerc√≠cio 6: Dashboards com Chain-of-thoughts\n",
    "\n",
    "Utilize 3 etapas de Chain-of-Thought prompting para escrever o c√≥digo inicial do dashboard, destacando as abas Overview, Despesas e Proposi√ß√µes. Explique o objetivo de cada prompt na evolu√ß√£o do c√≥digo at√© o arquivo dashboard.py final:\n",
    "\n",
    "- A aba Overview deve possuir um t√≠tulo e descri√ß√£o da solu√ß√£o de sua escolha.\n",
    "- O painel deve mostrar o texto sumarizado em config.yaml\n",
    "- O painel deve mostrar o gr√°fico de barras em docs/distribuicao_deputados.png\n",
    "- O painel deve mostrar os insights do LLM sobre a distribui√ß√£o de deputados em data/insights_distribuicao_deputados.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìù Os c√≥digos se encontram em `dataprep.py` e `dashboard.py`.\n",
    "> \n",
    "> No primeiro prompt, a ideia foi criar o arquivo inicial com um esqueleto geral de como tudo deveria ser organizado, j√° incluindo o t√≠tulo e o sum√°rio gerado anteriormente.\n",
    "> \n",
    "> No segundo prompt, eu estava interessado apenas no c√≥digo para exibir a imagem do gr√°fico, ent√£o informei ao LLM sobre a exist√™ncia do dashboard anterior, para que o foco fosse exclusivamente na inclus√£o dessa imagem.\n",
    "> \n",
    "> O √∫ltimo prompt seguiu uma l√≥gica semelhante √† do anterior, mas com foco em exibir os insights salvos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exerc√≠cio 7: Dashboards com Batch-prompting\n",
    "\n",
    "Utilize a t√©cnica de Batch-prompting para escrever o c√≥digo streamlit que preencha as abas Despesas e Proposi√ß√µes do c√≥digo em dashboard.py. O prompt deve descrever com detalhes cada aba para gera√ß√£o de:\n",
    "\n",
    "- Aba Despesas deve mostrar os insights sobre as despesas dos deputados (data/insights_despesas_deputados.json)\n",
    "- Aba Despesas deve conter um st.selectbox para sele√ß√£o do deputado.\n",
    "- Aba Despesas deve mostrar gr√°fico de barras com a s√©rie temporal de despesas do deputado selecionado (data/serie_despesas_di√°rias_deputados.parquet).\n",
    "- O painel deve mostrar uma tabela com os dados das proposi√ß√µes (data/proposicoes_deputados.parquet)\n",
    "- O painel deve mostrar o resumo das proposi√ß√µes em (data/sumarizacao_proposicoes.json)\n",
    "- Compare o resultado dos c√≥digos gerados pelas t√©cnicas de Chain-of-Thoughts e Batch-prompting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìù Os c√≥digos se encontram em `dataprep.py` e `dashboard.py`.\n",
    "> \n",
    ">\n",
    "> Acredito que essa t√©cnica seja superior ao COT (pelo menos neste caso), pois considero que a LLM tenha mais contexto para gerar um c√≥digo mais eficiente e que se conecte melhor. No COT, √© necess√°rio ficar relembrando a LLM sobre o que j√° foi feito e dar dicas do que n√£o refazer, evitando processamento desnecess√°rio.  \\\n",
    "> No batch, fica mais f√°cil fazer ajustes finos no prompt final sem se preocupar que isso afete os prompts seguintes.\n",
    "> Por outro lado, acredito que o batch prompting requeira mais processamento e possa exaurir a mem√≥ria da LLM se feito de forma exagerada.  \\\n",
    "> Em termos de funcionalidade, as duas t√©cnicas geraram um c√≥digo final que funcionou."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
