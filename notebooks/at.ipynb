{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AT - Engenharia de Prompts para Ciência de Dados [24E4_4]\n",
    "\n",
    "**Rafael Soares de Oliveira**\n",
    "\n",
    "Infnet - Ciência de Dados | Dezembro 2024\n",
    "\n",
    "https://lms.infnet.edu.br/moodle/mod/assign/view.php?id=413838\n",
    "\n",
    "> 💡 **Repositório GitHub:** https://github.com/RafaelOlivra/infnet-at-engenharia-de-prompts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercício 1: Arquitetura da Solução\n",
    "\n",
    "Desenvolva um prompt que utilize few-shot learning para classificar comentários como “Positivos”, “Neutros” ou “Negativos”. Inclua três exemplos de cada categoria no prompt e solicite ao LLM que classifique a frase \"Este episódio é divertido, mas não tão bom quanto os antigos.\". Interprete o resultado.\n",
    "\n",
    "Desenhe a arquitetura da solução com o programa da sua escolha. A arquitetura deve indicar os pontos de processamento de informação, LLMs utilizados, bases de dados (parquets, jsons e faiss), arquivos de configuração (yaml), abas do dashboard e suas funcionalidades.\n",
    "\n",
    "-   Exporte a arquitetura para o arquivo pdf importado no sistema.\n",
    "-   Descreva a arquitetura, explicando seus pontos importantes.\n",
    "-   Descreva o funcionamento de LLMs e como isso pode ser utilizado para atividades de sumarização.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Diagrama](./images/exec1-diagrama-aplicacao.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📝 O dashboard utiliza dados extraídos da API da Câmara dos Deputados (https://dadosabertos.camara.leg.br/api/v2/). Esses dados são processados no arquivo dataprep.py, onde ocorre a geração, sumarização e indexação de conteúdo com o auxílio do LLM Gemini e do vetorizador FAISS. Após o processamento, os dados são exportados nos formatos .parquet e .json.\n",
    ">\n",
    "> No arquivo dashboard.py, foi desenvolvido um aplicativo Streamlit com três abas principais: Overview, Despesas e Proposições. Essas abas utilizam os dados previamente preparados para criar uma interface interativa que facilita a visualização das informações.\n",
    "> \n",
    "> Na aba Proposições, há também uma interface de chat integrada com o LLM Gemini. Essa funcionalidade permite que o usuário faça perguntas e obtenha insights sobre os dados processados, utilizando um sistema RAG (Retrieval-Augmented Generation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📝 Large Language Models (LLMs) são modelos de inteligência artificial treinados em grandes volumes de texto para entender e gerar linguagem natural. Eles utilizam mecanismos como atenção para identificar as partes mais relevantes de um texto, tornando-se ideais para tarefas como geração de conteúdo e sumarização.\n",
    ">\n",
    "> Na geração de texto, os LLMs podem criar conteúdos originais, como respostas em chats, artigos ou relatórios, adaptando-se ao contexto e até podendo gerar textos com base em um estilo desejado.\n",
    "Na sumarização, os LLMs condensam textos extensos, destacando informações importantes ou ainda reformulando o conteúdo de forma mais clara. Isso é útil em aplicações como dashboards e chats, onde resumos e textos personalizados facilitam a análise, a comunicação e a tomada de decisões."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercício 2: Criação de Textos com LLMs\n",
    "\n",
    "Utilize a sua conta no “poe.com” para gerar um texto curto (2 parágrafos) que explique a Câmara dos Deputados. Execute o mesmo prompt com 3 LLMs diferentes (claude, gemini e chatgpt) e:\n",
    "\n",
    "-   Explique as vantagens e desvantagens dos três LLMs escolhidos.\n",
    "-   Argumente sobre a diferença entre a resposta dos 3 LLMs\n",
    "-   Justifique a escolha da resposta final\n",
    "\n",
    "-   Atualize o prompt do LLM final para gerar um arquivo data/config.yaml com a resposta final (chave: overview_summary).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Claude**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Claude](./images/exec2-a.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gemini**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Gemini](./images/exec2-b.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chat GPT**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ChatGPT](./images/exec2-c.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📝 O ChatGPT, desenvolvido pela OpenAI, é atualmente a principal escolha para tarefas cotidianas, como ajuda na redação de textos, correções e esclarecimento de dúvidas básicas. Ele possui um entendimento amplo sobre uma vasta gama de tópicos, gerando textos coerentes e com naturalidade impressionante. Baseado na arquitetura GPT-4, o ChatGPT é uma ferramenta poderosa. No entanto, apesar de todos esses avanços, ainda pode produzir respostas incorretas ou enviesadas dependendo do prompt utilizado. Além disso, seu custo é mais elevado em comparação com concorrentes.\n",
    ">\n",
    "> O Gemini, desenvolvido pela Google, destaca-se por produzir respostas concisas e seguras, contando com diversos filtros para bloquear conteúdos inadequados. Projetado para minimizar vieses em suas respostas, o Gemini também se diferencia por sua arquitetura multimodal, permitindo combinar texto, imagens e outros formatos de dados de maneira integrada. Uma desvantagem relevante é a forma como os dados fornecidos pelos usuários podem ser utilizados, já que a Google declara que essas informações podem ser usadas para melhorar seus produtos e serviços, o que, em alguns casos, levanta preocupações sobre invasão de privacidade.\n",
    ">\n",
    "> O Claude, criado pela Anthropic, é outro chatbot projetado com foco em segurança e princípios éticos incorporados. Ele se adapta bem a contextos mais específicos e, até o momento, oferece modelos com custos mais acessíveis (Dependendo do modelo), entregando um bom custo-benefício. No entanto, uma limitação do Claude é a menor presença de sua comunidade no conteúdo em português, o que pode representar uma desvantagem em soluções voltadas para o mercado local.\n",
    "\n",
    "> 📝 A resposta do Claude foi um pouco mais breve do que o esperado, deixando a desejar em alguns aspectos. Já as respostas do Gemini e do ChatGPT foram bastante similares, tanto no formato quanto no conteúdo, que foi satisfatório em ambos os casos.\n",
    "\n",
    "> 📝 Optei por seguir com a resposta do ChatGPT por considerá-la mais concisa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Geração de Yaml](./images/exec2-d.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercício 3: Processamento dos dados de deputados\n",
    "\n",
    "Implemente em dataprep.py uma função que faça a coleta das informações dos deputados atuais da câmara dos deputados:\n",
    "\n",
    "-   Colete e salve os dados dos deputados atuais da câmara no arquivo data/deputados.parquet através da url: url_base+/deputados\n",
    "-   Executar prompt para criar o código que gere um gráfico de pizza com o total e o percentual de deputados de cada partido, salvo em 'docs/distribuicao_deputados.png\n",
    "-   Executar prompt utilizando os resultados da análise anterior (distribuição de deputados por partido) para gerar insights sobre a distribuição de partidos e como isso influencia a câmara. Utilize os elementos de prompts dados, persona e exemplos para instruir o LLM. Explique o objetivo de cada elemento, avalie a resposta e salve-a em data/insights_distribuicao_deputados.json.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📝 A resposta se encontra em `dataprep.py`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercício 4: Processamento dos dados de despesas\n",
    "\n",
    "Implemente em dataprep.py uma função que colete as informações das despesas dos deputados atuais da câmara dos deputados no período de referência da solução (use a url: url_base+/deputados/{id}/despesas).\n",
    "\n",
    "-   Agrupe os dados de despesas por dia, deputado e tipo de despesa e salve num arquivo parquet (data/serie_despesas_diárias_deputados.parquet).\n",
    "-   Utilizando a técnica de prompt-chaining, crie um prompt que instrua o LLM a gerar um código python que analise os dados das despesas dos deputados. Peça para o LLM até 3 análises. Indique ao LLM quais dados estão disponíveis e o respectivo arquivo (salvo em a)) e execute as análises.\n",
    "-   Utilize os resultados das 3 análises para criar um prompt usando a técnica de Generated Knowledge para instruir o LLM a gerar insights. Salve o resultado como um JSON (data/insights_despesas_deputados.json).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📝 A resposta se encontra em `dataprep.py`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercício 5: Processamento dos dados de proposições\n",
    "\n",
    "Implemente em dataprep.py uma função que faça a coleta das informações das proposições que tramitam no período de referência (dataInicio e dataFim) e são do tema 'Economia', 'Educação' e 'Ciência, Tecnologia e Inovação' (códigos [40, 46, 62]).\n",
    "\n",
    "-   Coletar um total de 10 proposiçoes por tema e salvar em data/proposicoes_deputados.parquet\n",
    "-   Utilize a sumarização por chunks para resumir as proposições tramitadas no período de referência. Avalie a resposta e salve-a em data/sumarizacao_proposicoes.json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📝 A resposta se encontra em `dataprep.py`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercício 6: Dashboards com Chain-of-thoughts\n",
    "\n",
    "Utilize 3 etapas de Chain-of-Thought prompting para escrever o código inicial do dashboard, destacando as abas Overview, Despesas e Proposições. Explique o objetivo de cada prompt na evolução do código até o arquivo dashboard.py final:\n",
    "\n",
    "-   A aba Overview deve possuir um título e descrição da solução de sua escolha.\n",
    "-   O painel deve mostrar o texto sumarizado em config.yaml\n",
    "-   O painel deve mostrar o gráfico de barras em docs/distribuicao_deputados.png\n",
    "-   O painel deve mostrar os insights do LLM sobre a distribuição de deputados em data/insights_distribuicao_deputados.json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📝 Os códigos se encontram em `dataprep.py` e `dashboard.py`.\n",
    ">\n",
    "> No primeiro prompt, a ideia foi criar o arquivo inicial com um esqueleto geral de como tudo deveria ser organizado, já incluindo o título e o sumário gerado anteriormente.\n",
    ">\n",
    "> No segundo prompt, eu estava interessado apenas no código para exibir a imagem do gráfico, então informei ao LLM sobre a existência do dashboard anterior, para que o foco fosse exclusivamente na inclusão dessa imagem.\n",
    ">\n",
    "> O último prompt seguiu uma lógica semelhante à do anterior, mas com foco em exibir os insights salvos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercício 7: Dashboards com Batch-prompting\n",
    "\n",
    "Utilize a técnica de Batch-prompting para escrever o código streamlit que preencha as abas Despesas e Proposições do código em dashboard.py. O prompt deve descrever com detalhes cada aba para geração de:\n",
    "\n",
    "-   Aba Despesas deve mostrar os insights sobre as despesas dos deputados (data/insights_despesas_deputados.json)\n",
    "-   Aba Despesas deve conter um st.selectbox para seleção do deputado.\n",
    "-   Aba Despesas deve mostrar gráfico de barras com a série temporal de despesas do deputado selecionado (data/serie_despesas_diárias_deputados.parquet).\n",
    "-   O painel deve mostrar uma tabela com os dados das proposições (data/proposicoes_deputados.parquet)\n",
    "-   O painel deve mostrar o resumo das proposições em (data/sumarizacao_proposicoes.json)\n",
    "-   Compare o resultado dos códigos gerados pelas técnicas de Chain-of-Thoughts e Batch-prompting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📝 Os códigos se encontram em `dataprep.py` e `dashboard.py`.\n",
    ">\n",
    "> Acredito que essa técnica seja superior ao COT (pelo menos neste caso), pois considero que a LLM tenha mais contexto para gerar um código mais eficiente e que se conecte melhor. No COT, é necessário ficar relembrando a LLM sobre o que já foi feito e dar dicas do que não refazer, evitando processamento desnecessário. \\\n",
    "> No batch, fica mais fácil fazer ajustes finos no prompt final sem se preocupar que isso afete os prompts seguintes.\n",
    "> Por outro lado, acredito que o batch prompting requeira mais processamento e possa exaurir a memória da LLM se feito de forma exagerada. \\\n",
    "> Em termos de funcionalidade, as duas técnicas geraram um código final que funcionou.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercício 8: Dashboards com Batch-prompting\n",
    "\n",
    "Adicione ao código da aba Proposições uma interface para chat com um assistente virtual especialista em câmara dos deputados. As informações coletadas dos deputados, despesas e proposições (e suas sumarizações) devem ser vetorizadas usando o modelo \"neuralmind/bert-base-portuguese-cased\" para armazenamento na base vetorial FAISS. O prompt do sistema para o assistente virtual deve ser feito com a técnica Self-Ask:\n",
    "\n",
    "-   Explique como a técnica de self-ask pode ser utilizada nesse contexto.\n",
    "-   Avalie o resultado do modelo para as seguintes perguntas:\n",
    "    -   Qual é o partido político com mais deputados na câmara?\n",
    "    -   Qual é o deputado com mais despesas na câmara?\n",
    "    -   Qual é o tipo de despesa mais declarada pelos deputados da câmara?\n",
    "    -   Quais são as informações mais relevantes sobre as proposições que falam de Economia?\n",
    "    -   Quais são as informações mais relevantes sobre as proposições que falam de 'Ciência, Tecnologia e Inovação'?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📝 Os códigos se encontram em `dashboard.py`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Exec 8a](./images/exec8-a.png)\n",
    "\n",
    "> 📝 A resposta está errada! Porém a conclusão do modelo bate com os dados que ele recebeu do RAG. O modelo acabou informando o usuário sobre esse limitação, o que achei interessante.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Exec 8b](./images/exec8-b.png)\n",
    "\n",
    "> 📝 De forma similar a resposta anterior, o modelo respondeu corretamente se considerado apenas o RAG. Porém não dá para ter certeza, visto que os dados que o modelo recebeu são limitados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Exec 8c](./images/exec8-c.png)\n",
    "\n",
    "> 📝 Novamente acredito que o modelo se saiu bem, porém a quantidade de dados fornecida pelo RAG é limitada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Exec 8d](./images/exec8-d.png)\n",
    "\n",
    "> 📝 Acredito que o modelo se saiu muito bem nessa questão, dando um resumo bem satisfatório.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Exec 8e](./images/exec8-e.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📝 Gostei da reposta, o modelo utilizou muito bem os dados fornecidos pelo RAG e trouxe um resumo bem satisfatório.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercício 9: Geração de Imagens com Prompts\n",
    "\n",
    "Utilizando as informações sumarizadas das proposições dos deputados, vamos gerar prompts que possam fazer alusão aos temas e o que está sendo proposto. Use o google Colab para gerar imagens com o modelo \"CompVis/stable-diffusion-v1-4\" para duas proposições de sua escolha. Com essas informações, responda:\n",
    "\n",
    "Descreva o funcionamento dos modelo de imagem, segundo suas arquiteturas, limitações e vantagens:\n",
    "Stable Diffusion\n",
    "DALL-e\n",
    "MidJourney\n",
    "Utilize diferentes técnicas de “Estilo Visual” e “Composição”, além de exemplos com negative prompting, para gerar 3 versões de imagem para cada proposição e avalie as diferenças entre os resultados (as imagens) e os prompts (as proposições).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📝 Link para o colab: https://colab.research.google.com/drive/1Fj5JJSbotnVDR1HgjE4uycv5vjUllZlT?usp=sharing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📝 Stable Diffusion é um modelo open-source baseado em difusão latente, eficiente em termos de computação e capaz de rodar em GPUs comuns. Ele suporta técnicas como inpainting e prompting negativo, mas geralmente apresenta qualidade inferior em comparação a modelos mais especializados.\n",
    ">\n",
    "> DALL-E utiliza uma arquitetura baseada em Transformers para gerar imagens a partir de descrições textuais. É um modelo bastante eficaz na interpretação de prompts, mas possui certa limitação quanto à personalização e requer um domínio de técnicas avançadas de composição. A qualidade das imagens pode variar bastante.\n",
    ">\n",
    "> MidJourney é desenvolvido pela MidJourney, Inc. Ele é otimizado para criar imagens estilizadas e com estética artística, e possui uma abordagem amigável, operando através de chats no Discord. Possui menor precisão para descrições técnicas e detalhadas. É um serviço pago e de código fechado, embora permita a criação de algumas imagens no free-tier.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
